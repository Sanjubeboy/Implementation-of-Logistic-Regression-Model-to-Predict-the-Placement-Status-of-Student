{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fqV35KEAqPH",
        "outputId": "55347174-8140-4e56-853b-119a9b82d5b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Placement data\n",
            "   sl_no gender  ssc_p    ssc_b  hsc_p    hsc_b     hsc_s  degree_p  \\\n",
            "0      1      M  67.00   Others  91.00   Others  Commerce     58.00   \n",
            "1      2      M  79.33  Central  78.33   Others   Science     77.48   \n",
            "2      3      M  65.00  Central  68.00  Central      Arts     64.00   \n",
            "3      4      M  56.00  Central  52.00  Central   Science     52.00   \n",
            "4      5      M  85.80  Central  73.60  Central  Commerce     73.30   \n",
            "\n",
            "    degree_t workex  etest_p specialisation  mba_p      status    salary  \n",
            "0   Sci&Tech     No     55.0         Mkt&HR  58.80      Placed  270000.0  \n",
            "1   Sci&Tech    Yes     86.5        Mkt&Fin  66.28      Placed  200000.0  \n",
            "2  Comm&Mgmt     No     75.0        Mkt&Fin  57.80      Placed  250000.0  \n",
            "3   Sci&Tech     No     66.0         Mkt&HR  59.43  Not Placed       NaN  \n",
            "4  Comm&Mgmt     No     96.8        Mkt&Fin  55.50      Placed  425000.0  \n",
            "2. Salary Data\n",
            "  gender  ssc_p    ssc_b  hsc_p    hsc_b     hsc_s  degree_p   degree_t  \\\n",
            "0      M  67.00   Others  91.00   Others  Commerce     58.00   Sci&Tech   \n",
            "1      M  79.33  Central  78.33   Others   Science     77.48   Sci&Tech   \n",
            "2      M  65.00  Central  68.00  Central      Arts     64.00  Comm&Mgmt   \n",
            "3      M  56.00  Central  52.00  Central   Science     52.00   Sci&Tech   \n",
            "4      M  85.80  Central  73.60  Central  Commerce     73.30  Comm&Mgmt   \n",
            "\n",
            "  workex  etest_p specialisation  mba_p      status  \n",
            "0     No     55.0         Mkt&HR  58.80      Placed  \n",
            "1    Yes     86.5        Mkt&Fin  66.28      Placed  \n",
            "2     No     75.0        Mkt&Fin  57.80      Placed  \n",
            "3     No     66.0         Mkt&HR  59.43  Not Placed  \n",
            "4     No     96.8        Mkt&Fin  55.50      Placed  \n",
            "3. Checking the null() function\n",
            "gender            0\n",
            "ssc_p             0\n",
            "ssc_b             0\n",
            "hsc_p             0\n",
            "hsc_b             0\n",
            "hsc_s             0\n",
            "degree_p          0\n",
            "degree_t          0\n",
            "workex            0\n",
            "etest_p           0\n",
            "specialisation    0\n",
            "mba_p             0\n",
            "status            0\n",
            "dtype: int64\n",
            "4. Data Duplicate\n",
            "0\n",
            "5. Print data\n",
            "     gender  ssc_p  ssc_b  hsc_p  hsc_b  hsc_s  degree_p  degree_t  workex  \\\n",
            "0         1  67.00      1  91.00      1      1     58.00         2       0   \n",
            "1         1  79.33      0  78.33      1      2     77.48         2       1   \n",
            "2         1  65.00      0  68.00      0      0     64.00         0       0   \n",
            "3         1  56.00      0  52.00      0      2     52.00         2       0   \n",
            "4         1  85.80      0  73.60      0      1     73.30         0       0   \n",
            "..      ...    ...    ...    ...    ...    ...       ...       ...     ...   \n",
            "210       1  80.60      1  82.00      1      1     77.60         0       0   \n",
            "211       1  58.00      1  60.00      1      2     72.00         2       0   \n",
            "212       1  67.00      1  67.00      1      1     73.00         0       1   \n",
            "213       0  74.00      1  66.00      1      1     58.00         0       0   \n",
            "214       1  62.00      0  58.00      1      2     53.00         0       0   \n",
            "\n",
            "     etest_p  specialisation  mba_p  status  \n",
            "0       55.0               1  58.80       1  \n",
            "1       86.5               0  66.28       1  \n",
            "2       75.0               0  57.80       1  \n",
            "3       66.0               1  59.43       0  \n",
            "4       96.8               0  55.50       1  \n",
            "..       ...             ...    ...     ...  \n",
            "210     91.0               0  74.49       1  \n",
            "211     74.0               0  53.62       1  \n",
            "212     59.0               0  69.72       1  \n",
            "213     70.0               1  60.23       1  \n",
            "214     89.0               1  60.22       0  \n",
            "\n",
            "[215 rows x 13 columns]\n",
            "6. Data-status\n",
            "     gender  ssc_p  ssc_b  hsc_p  hsc_b  hsc_s  degree_p  degree_t  workex  \\\n",
            "0         1  67.00      1  91.00      1      1     58.00         2       0   \n",
            "1         1  79.33      0  78.33      1      2     77.48         2       1   \n",
            "2         1  65.00      0  68.00      0      0     64.00         0       0   \n",
            "3         1  56.00      0  52.00      0      2     52.00         2       0   \n",
            "4         1  85.80      0  73.60      0      1     73.30         0       0   \n",
            "..      ...    ...    ...    ...    ...    ...       ...       ...     ...   \n",
            "210       1  80.60      1  82.00      1      1     77.60         0       0   \n",
            "211       1  58.00      1  60.00      1      2     72.00         2       0   \n",
            "212       1  67.00      1  67.00      1      1     73.00         0       1   \n",
            "213       0  74.00      1  66.00      1      1     58.00         0       0   \n",
            "214       1  62.00      0  58.00      1      2     53.00         0       0   \n",
            "\n",
            "     etest_p  specialisation  mba_p  \n",
            "0       55.0               1  58.80  \n",
            "1       86.5               0  66.28  \n",
            "2       75.0               0  57.80  \n",
            "3       66.0               1  59.43  \n",
            "4       96.8               0  55.50  \n",
            "..       ...             ...    ...  \n",
            "210     91.0               0  74.49  \n",
            "211     74.0               0  53.62  \n",
            "212     59.0               0  69.72  \n",
            "213     70.0               1  60.23  \n",
            "214     89.0               1  60.22  \n",
            "\n",
            "[215 rows x 12 columns]\n",
            "7. y_prediction array\n",
            "LogisticRegression(solver='liblinear')\n",
            "[0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1\n",
            " 1 1 1 0 0 1]\n",
            "8. Accuracy\n",
            "0.813953488372093\n",
            "9. Confusion array\n",
            "[[11  5]\n",
            " [ 3 24]]\n",
            "10. Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.69      0.73        16\n",
            "           1       0.83      0.89      0.86        27\n",
            "\n",
            "    accuracy                           0.81        43\n",
            "   macro avg       0.81      0.79      0.80        43\n",
            "weighted avg       0.81      0.81      0.81        43\n",
            "\n",
            "[1]\n",
            "11. Prediction of LR\n",
            "[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"Placement_Data.csv\")\n",
        "\n",
        "print(\"1. Placement data\")\n",
        "print(data.head())\n",
        "\n",
        "\n",
        "data1 = data.copy()\n",
        "data1= data1.drop([\"sl_no\",\"salary\"],axis=1)\n",
        "\n",
        "print(\"2. Salary Data\")\n",
        "print(data1.head())\n",
        "\n",
        "print(\"3. Checking the null() function\")\n",
        "print(data1.isnull().sum())\n",
        "\n",
        "print(\"4. Data Duplicate\")\n",
        "print(data1.duplicated().sum())\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lc = LabelEncoder()\n",
        "\n",
        "data1[\"gender\"] = lc.fit_transform(data1[\"gender\"])\n",
        "data1[\"ssc_b\"] = lc.fit_transform(data1[\"ssc_b\"])\n",
        "data1[\"hsc_b\"] = lc.fit_transform(data1[\"hsc_b\"])\n",
        "data1[\"hsc_s\"] = lc.fit_transform(data1[\"hsc_s\"])\n",
        "data1[\"degree_t\"]=lc.fit_transform(data[\"degree_t\"])\n",
        "data1[\"workex\"] = lc.fit_transform(data1[\"workex\"])\n",
        "data1[\"specialisation\"] = lc.fit_transform(data1[\"specialisation\"])\n",
        "data1[\"status\"]=lc.fit_transform(data1[\"status\"])\n",
        "\n",
        "\n",
        "print(\"5. Print data\")\n",
        "print(data1)\n",
        "\n",
        "y = data1[\"status\"]\n",
        "print(\"6. Data-status\")\n",
        "x = data1.iloc[:,:-1]\n",
        "print(x)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=0)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression(solver=\"liblinear\")\n",
        "\n",
        "print(\"7. y_prediction array\")\n",
        "print(lr.fit(x_train,y_train))\n",
        "y_pred = lr.predict(x_test)\n",
        "print(y_pred)\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "print(\"8. Accuracy\")\n",
        "print(accuracy)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion = confusion_matrix(y_test,y_pred)\n",
        "print(\"9. Confusion array\")\n",
        "print(confusion)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "classification_report1 = classification_report(y_test,y_pred)\n",
        "\n",
        "print(\"10. Classification report\")\n",
        "print(classification_report1)\n",
        "\n",
        "prediction = [1,67,1,91,1,1,58,2,0,55,1,58.80]\n",
        "print(lr.predict([prediction])) \n",
        "\n",
        "\n",
        "prediction = [1,80,1,90,1,1,90,1,0,85,1,85]\n",
        "print(\"11. Prediction of LR\")\n",
        "print(lr.predict([prediction])) "
      ]
    }
  ]
}